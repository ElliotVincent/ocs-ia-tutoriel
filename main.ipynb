{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5767d8c-d402-4d8b-8c56-0cc2d1cbd62a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import glob\n",
    "import warnings\n",
    "import torch \n",
    "import numpy as np \n",
    "import copy\n",
    "import sklearn\n",
    "\n",
    "# Choisir entre Cairanne_84, Chateauroux_36, Chissey_71, Claveyson_26, Fessenheim_68, \n",
    "# MaelPestivien_22, SaintCyr_69, SaintHilaire_61, SaintMartin_15, Sauvagnon_64\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train_zone = 'Sauvagnon_64'\n",
    "val_zone = 'MaelPestivien_22'\n",
    "test_zone = 'Chateauroux_36'\n",
    "\n",
    "def load_images(zone):\n",
    "    images_paths = glob.glob(f\"sample/{zone}/IMG_*.jpg\")\n",
    "    annotations_paths = [path.replace('IMG', 'MSK').replace('jpg', 'tif') for path in images_paths]\n",
    "    imgs = torch.stack([torch.tensor(rasterio.open(image).read()).float() for image in images_paths])\n",
    "    annots_19 = torch.stack([torch.tensor(rasterio.open(annot).read()[0]).int() for annot in annotations_paths]) - 1\n",
    "    mapping_19_to_4_classes = torch.tensor([0, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 1, 2, 4, 4, 4, 4, 4, 4])\n",
    "    annots_5 = mapping_19_to_4_classes[annots_19]\n",
    "    return imgs, annots_19, annots_5\n",
    "    \n",
    "images_paths = glob.glob(f\"sample/{train_zone}/IMG_*.jpg\")\n",
    "annotations_paths = [path.replace('IMG', 'MSK').replace('jpg', 'tif') for path in images_paths]\n",
    "\n",
    "rvb_mapping_19_classes = torch.tensor([[219, 14, 154], [147, 142, 123], [248, 12, 0], [169, 113, 1], [21, 83, 174], [25, 74, 38], [70, 228, 131],\n",
    "                                   [243, 166, 13], [102, 0, 130], [85, 255, 0], [255, 243, 13], [228, 223, 124], [61, 230, 235], [255, 255, 255],\n",
    "                                   [138, 179, 160], [107, 113, 79], [197, 220, 66], [153, 153, 255], [0, 0, 0]])\n",
    "rvb_mapping_5_classes = torch.tensor([[255, 65, 54], [241, 196, 15], [52, 152, 219], [46, 204, 113], [0, 0, 0]])\n",
    "\n",
    "def plot_images(imgs, annots, mapping, preds=None):\n",
    "    n_rows = 2 if preds is None else 3\n",
    "    for k, (image, annotation) in enumerate(zip(imgs, annots)):\n",
    "        img = image.permute(1,2,0).int()\n",
    "        annotation = mapping[annotation]\n",
    "        plt.subplot(n_rows, 3, k + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(n_rows, 3, 3 + k + 1)\n",
    "        plt.imshow(annotation)\n",
    "        plt.axis('off')\n",
    "        if preds is not None:\n",
    "            pred = mapping[preds[k]]\n",
    "            plt.subplot(n_rows, 3, 6 + k + 1)\n",
    "            plt.imshow(pred)\n",
    "            plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "train_images, train_annotations_19, train_annotations = load_images(train_zone)\n",
    "val_images, val_annotations_19, val_annotations = load_images(val_zone)\n",
    "test_images, test_annotations_19, test_annotations = load_images(test_zone)\n",
    "\n",
    "plot_images(train_images, train_annotations, rvb_mapping_5_classes)\n",
    "plot_images(val_images, val_annotations, rvb_mapping_5_classes)\n",
    "plot_images(test_images, test_annotations, rvb_mapping_5_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d49d4d6-9ac3-4238-a5d7-14e094274615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(torch.nn.Conv2d(3, 4, 7, padding=3, dilation=1, groups=1, bias=True, padding_mode='reflect', device='cuda'),\n",
    "                            torch.nn.ReLU()\n",
    "                           )\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model) # 3 * 4 * 7 * 7 + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1df4cbe-170c-4f0f-aa15-d58e1ed1a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, std = torch.cat([train_images, val_images]).mean((0, 2, 3)), torch.cat([train_images, val_images]).std((0, 2, 3))\n",
    "\n",
    "normed_train_images = (train_images - mean[..., None, None]) / std[..., None, None]\n",
    "normed_val_images = (val_images - mean[..., None, None]) / std[..., None, None]\n",
    "normed_test_images = (test_images - mean[..., None, None]) / std[..., None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49709cbd-0df3-4420-8871-8800cfec201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_train_images = normed_train_images.to('cuda')\n",
    "train_annotations = train_annotations.to('cuda')\n",
    "\n",
    "normed_val_images = normed_val_images.to('cuda')\n",
    "val_annotations = val_annotations.to('cuda')\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"max\")\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=4)\n",
    "\n",
    "train_accs, val_accs = [], []\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = torch.inf\n",
    "best_model = None\n",
    "for i in range(1, 101):     \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(normed_train_images)\n",
    "    pred = torch.argmax(out, dim=1)\n",
    "    loss = criterion(out, train_annotations)\n",
    "    acc = (pred == train_annotations).sum() / (512*512*3) * 100\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(acc)\n",
    "    train_losses.append(float(loss.item()))\n",
    "    train_accs.append(float(acc.item()))\n",
    "    if i % 5 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            out = model(normed_val_images)\n",
    "            pred = torch.argmax(out, dim=1)\n",
    "            val_loss = float(criterion(out, val_annotations).item())\n",
    "            val_losses.append(val_loss)\n",
    "            val_accs.append(float((pred == val_annotations).sum() / (512*512*3) * 100))\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_model = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ceca1-5ee0-4e06-8419-0fc75140e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 101), train_accs)\n",
    "plt.plot(range(5, 101, 5), val_accs)\n",
    "plt.show()\n",
    "plt.plot(range(1, 101), train_losses)\n",
    "plt.plot(range(5, 101, 5), val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc61e5e-364b-41d6-8fbe-a2aae4dda6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(normed_val_images.to('cuda'))\n",
    "    pred = torch.argmax(out, dim=1)\n",
    "conf_mat = sklearn.metrics.confusion_matrix(val_annotations.flatten().numpy(), pred.cpu().flatten().numpy(), labels=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0ca26-a139-4542-9f5d-86d9062c3d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(test_images, test_annotations, rvb_mapping_5_classes, pred.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa75c7-628a-4dd4-b144-76a74366d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc = np.trace(conf_mat) / np.sum(conf_mat) * 100\n",
    "per_class_acc = np.diag(conf_mat) / (conf_mat.sum(axis=1) + 1e-17) * 100\n",
    "mean_acc = np.mean(per_class_acc) \n",
    "\n",
    "print(f\"Overall Accuracy: {overall_acc:.4f}\")\n",
    "print(f\"Mean Accuracy: {mean_acc:.4f}\")\n",
    "print(f\"Per-class Accuracy: {per_class_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
